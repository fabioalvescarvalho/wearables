# Wearables: The Personal Display
Swedish Team wearables' project, for the 2015 NASA Space Apps Hackathon

___Speech-to-text functionality___
using the InputManager.dll and C# and XAML and our own Voice Engine and Triggers with System.Speech.Recognition and System.Speech.Synthesis

___Functional hardware prototype (MVP)___
Built using the Gadgeteer prototyping toolkit. Key files, describing the soft- and hardware, are found in the Gadgeteer_hardware folder.

_____________________________________________________________________________________________________________________________

THE PERSONAL DISPLAY TALK (PDTalk)

Technical report for The Personal Display Talk

Executive Summary
The Personal Display needed an eye tracking system (to be able to smoothly navigate text) and a microphone (in order to edit information through speech-to-text software). 
For further development using the Tobii EyeX for eye tracking system. The System is using .NET Framework 4.5¨

1: Introduction

We have developed a wearable device (The Personal Display) so that the user can interact intuitively with his or her environment in order to both obtain and edit location specific information without interrupting workflow. The innovation uses several current technologies such as Near Field Communication, Eye tracking and Speech-to-Text. Our functional hardware prototype captures both tactile and touchless user inputs.

2: Methodology

2.1. Experimental/sampling design

Frist of all The Personal Display Talk was developed in a small console C# program
For testing and verifying we did a the analysis of the console program is verified that 
It was Possible to do the commands we want to use we tested voice command’s
And how System.Speech.Recognition and System.Speech.Synthesis wood work 
Best way for the personal display.

2.2. Data analysis

Using Visual Studio 2013 Ultimate built in code analysis we saw 0 errors in our Console 
Program (see fig.1) so we decided to move the furniture with develop to a more advance  
Program using XAML with a Voice engine and Trigger for the commands (see fig.2).

3: Results

The result was with success we now have a beta of a Voice System that can be used on the Personal display at ISS and for further development using the Tobii EyeX as the Eye Tracking System.

4: Discussion

The Personal Display Talk is making it easier than ever for an astronaut’s to reed manuals on board the ISS
Just read the manual with your eyes and edit it with your voice we making it easier than read a big bunt of paper.

5: Conclusions

The conclusions drawn from there results, are that it is possible to make it easier to read big
Paper manual’s at ISS and edit the manuals.

6: Recommendations

We recommend a development of an eye tracking system that can integrate with the voice recognition system
References
MSDN: Speech Recognition (Microsoft.Speech)
https://msdn.microsoft.com/en-us/library/hh378380(v=office.14).aspx

Appendices
None
_____________________________________________________________________________________________________________________________
	






For further details of the project, see our project website
https://2015.spaceappschallenge.org/project/the-personal-display/
